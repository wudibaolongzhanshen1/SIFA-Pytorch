2024-08-23 16:25:31,540 - main.py[line:71] - INFO: target_val_dataset_path: D:/MyDataSet/CT2MR/PnpAda_release_data/pytorch/target_val_data
2024-08-23 16:25:31,540 - main.py[line:71] - INFO: source_val_dataset_path: D:/MyDataSet/CT2MR/PnpAda_release_data/pytorch/source_val_data
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: source_train_dataset_path: D:/MyDataSet/CT2MR/PnpAda_release_data/pytorch/source_train_data
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: target_train_dataset_path: D:/MyDataSet/CT2MR/PnpAda_release_data/pytorch/target_train_data
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: output_root_dir: ./output
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: pool_size: 50
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: _LAMBDA_A: 10
2024-08-23 16:25:31,541 - main.py[line:71] - INFO: _LAMBDA_B: 10
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: skip: 1
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: num_cls: 5
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: base_lr: 0.0002
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: max_step: 20000
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: keep_rate_value: 1.0
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: is_training_value: 1
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: batch_size: 4
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: lr_gan_decay: 0
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: to_restore: 0
2024-08-23 16:25:31,542 - main.py[line:71] - INFO: checkpoint_dir: ./checkpoint
